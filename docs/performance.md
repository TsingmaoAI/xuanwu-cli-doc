# 性能优化

## 资源分配策略

系统支持**模型自动放置与资源自适应**：

- 依据模型量化精度实时计算显存占用
- 结合 GPU 间通信距离智能选择推理引擎
- 自动分配最合适的显卡组合和最佳并行数量 (TP)

## 性能建议

1. **使用流式响应** - 改善用户体验，降低首字延迟
2. **合理设置 max_tokens** - 避免不必要的长生成
3. **批处理请求** - 对于多个独立问题，考虑并发请求
4. **模型预热** - 使用 `xw pull` 提前下载模型

## 显存管理

查看显存占用：

```bash
# 昇腾
npu-smi info

# 沐曦
musa-smi
```

释放显存：

```bash
xw stop <model>
```

## 张量并行度

选择合适的 GPU 数量：

| GPU 数量 | 适用模型 |
|----------|----------|
| 1 张卡 | 小模型 (≤13B) |
| 2 张卡 | 中型模型 (13B-34B) |
| 4 张卡 | 大模型 (34B-72B) |
| 8 张卡 | 超大模型 (≥72B) |

> 使用过多 GPU 会因通信开销降低性能。

## 并发请求

根据显存容量调整并发数：

- 910B (64GB)：约 4-8 并发 (取决于模型大小)
- 使用 `xw ps` 查看 VRAM 占用

## 故障排查

### 驱动问题

**症状**：驱动未安装或不可用

**解决**：

```bash
# 昇腾：检查驱动
npu-smi info

# 如无输出，重新安装驱动
```

### 显存不足

**症状**：`Out of memory` 错误

**解决**：

1. 减少并发请求
2. 使用更多 GPU (张量并行)
3. 使用更小的模型
4. 停止其他模型：`xw stop <model>`

## 限制

- 不支持 Function Calling (计划中)
- 并发请求数取决于模型参数量和 GPU 显存
